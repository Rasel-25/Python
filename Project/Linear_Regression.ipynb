{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 steps of Machine Learning\n",
    "1. Data gathering\n",
    "2. data preprocessing\n",
    "3. Exploratory Data Analysis (EDA)\n",
    "4. Feature engineering/selection\n",
    "5. Training model\n",
    "6. Test model/Model evaluation\n",
    "7. Hyper Parameter tuning\n",
    "8. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('FuelConsumption.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the basic info and missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return DataFrame with duplicate rows removed.\n",
    "data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count categorical unique value from make column\n",
    "data['MAKE'].value_counts()\n",
    "data.MAKE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count categorical unique value from MODEL column\n",
    "data['MODEL'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count categorical unique value from VEHICLECLASS column\n",
    "data['VEHICLECLASS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count categorical unique value from TRANSMISSION  column\n",
    "data['TRANSMISSION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['FUELTYPE'].unique() # getting the name of unique value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count categorical unique value from FUELTYPE  column\n",
    "data['FUELTYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['MODELYEAR'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop MODELYEAR COLUMN\n",
    "data.drop(columns=['MODELYEAR'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder=LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each column transform categorical to numerical value and  update to dataframe\n",
    "for col in ['MAKE','MODEL','VEHICLECLASS','TRANSMISSION','FUELTYPE']:\n",
    "    data[col]=encoder.fit_transform(data[col]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='white')\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.scatter(x=data['ENGINESIZE'],y=data['CO2EMISSIONS'])\n",
    "plt.title('ENGINSIZE VS C02EMISSIONS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.scatterplot(x='ENGINESIZE', y='CO2EMISSIONS', data=data)\n",
    "plt.title('ENGINESIZE VE CO2EMISSIONS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(data.ENGINESIZE,kde=False)\n",
    "data['ENGINESIZE'].plot(kind='hist') # hist/bar\n",
    "data.ENGINESIZE.plot(kind='hist') # by this plot we can know the distribution of data over x axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.pairplot(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxenplot(data=data, x='ENGINESIZE', )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Feature Engineering/Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation=data.corr()\n",
    "correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(correlation, annot=True,cmap='Greens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Droping unnecessary ffeatures/column\n",
    "data.drop(columns=['MAKE', 'MODEL', 'VEHICLECLASS', 'TRANSMISSION',\n",
    "          'FUELTYPE', 'FUELCONSUMPTION_COMB_MPG'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(correlation, annot=True,cmap='Greens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detect Quartile and remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1=np.percentile(data.ENGINESIZE, 25, method='midpoint')\n",
    "Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3=np.percentile(data.ENGINESIZE, 75, method='midpoint')\n",
    "Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iQR=Q3-Q1\n",
    "iQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3+1.5*iQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1-1.5*iQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Outliers_index_upper=np.where(data['ENGINESIZE']>Q3+1.5*iQR)\n",
    "Outliers_index_upper[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Outliers_index_lower=np.where(data['ENGINESIZE']<Q1-1.5*iQR)\n",
    "Outliers_index_lower[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Droping Outliers_index\n",
    "data.drop(Outliers_index_upper[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxenplot(data['ENGINESIZE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Training model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train & test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When ues a single feature for modeling then we called simple linear Regression,\n",
    "on the other hand when use one features for modeling then called multipul linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple linear rgression\n",
    "train_features, test_features, train_target, test_target = train_test_split(\n",
    "    data[['ENGINESIZE']], data[['CO2EMISSIONS']], test_size=0.2,random_state=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features\n",
    "test_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model=LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training our model\n",
    "model.fit(train_features,train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# theta 0\n",
    "model.intercept_ # intercept_ refers theta zero value, it will be always single value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# theta 1\n",
    "model.coef_ # coef_ means coefficient which refers theta one values , it may be multipul value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=test_features.values[0] # return ENGINESIZE OF ZERO INDEX\n",
    "yhat=model.intercept_ +(model.coef_*x) # mathematical calculation\n",
    "yhat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return CO2EMISSION OF ZERO INDEX\n",
    "test_target.values[0]   # .values[0]  conert Dataferm to numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Model testing and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score #sklearn.metrics contain all error evaluation module "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mannuly Error calculations\n",
    "y_hat=model.predict(test_features) # prediction\n",
    "np.sum((test_target - y_hat)**2)/213\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error calculation\n",
    "mean_squared_error(test_target,y_hat) # similar with previous one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test accuricy\n",
    "r2_score(test_target, y_hat) # or\n",
    "\n",
    "r2_score(test_target, y_hat)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking error and accurecy for single features\n",
    "for features in data.columns[:-1]:\n",
    "    print('__________')\n",
    "    train_features, test_features, train_target, test_target = train_test_split(\n",
    "    data[[features]], data[['CO2EMISSIONS']], test_size=0.2,random_state=2)\n",
    "\n",
    "    model=LinearRegression()\n",
    "    model.fit(train_features,train_target)\n",
    "    y_hat=model.predict(test_features)\n",
    "    print(f'ERROR OF {features}: ',mean_squared_error(test_target,y_hat))\n",
    "    print(f'ACCURICY OF {features}: ',r2_score(test_target, y_hat)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations # module of combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking error and accurecy for combine features\n",
    "feature_combinations = list(combinations(['ENGINESIZE', 'CYLINDERS','FUELCONSUMPTION_CITY',\n",
    "                            'FUELCONSUMPTION_HWY', 'FUELCONSUMPTION_COMB'], 3))  # 2 refers  numbers of combination\n",
    "for features in feature_combinations:\n",
    "    print('---------------')\n",
    "    train_features, test_features, train_target, test_target = train_test_split(\n",
    "        data[list(features)], data[['CO2EMISSIONS']], test_size=0.2,random_state=2)\n",
    "    model=LinearRegression()\n",
    "    model.fit(train_features,train_target)\n",
    "    y_hat=model.predict(test_features)\n",
    "    print(f'ERROR OF {features}: ',mean_squared_error(test_target,y_hat))\n",
    "    print(f'ACCURICY OF {features}: ',r2_score(test_target, y_hat)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " k-fold Cross-Validation\n",
    " \n",
    " Cross-validation is a statistical method used to estimate the skill of machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold # module of k-fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mInit signature:\u001b[0m \u001b[0mKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m     \n",
      "K-Folds cross-validator\n",
      "\n",
      "Provides train/test indices to split data in train/test sets. Split\n",
      "dataset into k consecutive folds (without shuffling by default).\n",
      "\n",
      "Each fold is then used once as a validation while the k - 1 remaining\n",
      "folds form the training set.\n",
      "\n",
      "Read more in the :ref:`User Guide <k_fold>`.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "n_splits : int, default=5\n",
      "    Number of folds. Must be at least 2.\n",
      "\n",
      "    .. versionchanged:: 0.22\n",
      "        ``n_splits`` default value changed from 3 to 5.\n",
      "\n",
      "shuffle : bool, default=False\n",
      "    Whether to shuffle the data before splitting into batches.\n",
      "    Note that the samples within each split will not be shuffled.\n",
      "\n",
      "random_state : int, RandomState instance or None, default=None\n",
      "    When `shuffle` is True, `random_state` affects the ordering of the\n",
      "    indices, which controls the randomness of each fold. Otherwise, this\n",
      "    parameter has no effect.\n",
      "    Pass an int for reproducible output across multiple function calls.\n",
      "    See :term:`Glossary <random_state>`.\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> import numpy as np\n",
      ">>> from sklearn.model_selection import KFold\n",
      ">>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
      ">>> y = np.array([1, 2, 3, 4])\n",
      ">>> kf = KFold(n_splits=2)\n",
      ">>> kf.get_n_splits(X)\n",
      "2\n",
      ">>> print(kf)\n",
      "KFold(n_splits=2, random_state=None, shuffle=False)\n",
      ">>> for train_index, test_index in kf.split(X):\n",
      "...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
      "...     X_train, X_test = X[train_index], X[test_index]\n",
      "...     y_train, y_test = y[train_index], y[test_index]\n",
      "TRAIN: [2 3] TEST: [0 1]\n",
      "TRAIN: [0 1] TEST: [2 3]\n",
      "\n",
      "Notes\n",
      "-----\n",
      "The first ``n_samples % n_splits`` folds have size\n",
      "``n_samples // n_splits + 1``, other folds have size\n",
      "``n_samples // n_splits``, where ``n_samples`` is the number of samples.\n",
      "\n",
      "Randomized CV splitters may return different results for each call of\n",
      "split. You can make the results identical by setting `random_state`\n",
      "to an integer.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "StratifiedKFold : Takes group information into account to avoid building\n",
      "    folds with imbalanced class distributions (for binary or multiclass\n",
      "    classification tasks).\n",
      "\n",
      "GroupKFold : K-fold iterator variant with non-overlapping groups.\n",
      "\n",
      "RepeatedKFold : Repeats K-Fold n times.\n",
      "\u001b[1;31mFile:\u001b[0m           c:\\python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py\n",
      "\u001b[1;31mType:\u001b[0m           ABCMeta\n",
      "\u001b[1;31mSubclasses:\u001b[0m     \n"
     ]
    }
   ],
   "source": [
    "KFold?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe().T"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2be5faf79681da6f2a61fdfdd5405d65d042280f7fba6178067603e3a2925119"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
